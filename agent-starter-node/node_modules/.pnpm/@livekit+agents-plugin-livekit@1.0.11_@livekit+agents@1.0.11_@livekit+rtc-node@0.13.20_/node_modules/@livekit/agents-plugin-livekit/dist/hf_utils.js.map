{"version":3,"sources":["../src/hf_utils.ts"],"sourcesContent":["// SPDX-FileCopyrightText: 2025 LiveKit, Inc.\n//\n// SPDX-License-Identifier: Apache-2.0\n\n/**\n * Fixed version of HuggingFace's downloadFileToCacheDir that matches Python's behavior\n *\n * Key fix: Uses branch/tag HEAD commit for snapshot paths, not file's last commit\n * This ensures all files from the same revision end up in the same snapshot folder\n */\nimport type { CommitInfo, PathInfo, RepoDesignation } from '@huggingface/hub';\nimport { downloadFile, listCommits, pathsInfo } from '@huggingface/hub';\nimport { log } from '@livekit/agents';\nimport { createWriteStream, writeFileSync } from 'node:fs';\nimport { lstat, mkdir, rename, stat } from 'node:fs/promises';\nimport { homedir } from 'node:os';\nimport { dirname, join, relative, resolve } from 'node:path';\nimport { Readable } from 'node:stream';\nimport { pipeline } from 'node:stream/promises';\nimport type { ReadableStream } from 'node:stream/web';\n\n// Define CredentialsParams if not exported\ninterface CredentialsParams {\n  accessToken?: string;\n}\n\nexport const REGEX_COMMIT_HASH: RegExp = new RegExp('^[0-9a-f]{40}$');\n\n// Helper functions from HuggingFace's cache-management\nfunction getHFHubCachePath(customCacheDir?: string): string {\n  return customCacheDir || join(homedir(), '.cache', 'huggingface', 'hub');\n}\n\nfunction getRepoFolderName(repoId: string): string {\n  return `models--${repoId.replace(/\\//g, '--')}`;\n}\n\nfunction toRepoId(repo: RepoDesignation | string): string {\n  if (typeof repo === 'string') {\n    return repo;\n  }\n  return `${repo.name}`;\n}\n\n/**\n * Get the HEAD commit hash for a branch/tag (matching Python's behavior)\n */\nasync function getBranchHeadCommit(\n  repo: RepoDesignation,\n  revision: string,\n  params: { accessToken?: string; hubUrl?: string; fetch?: typeof fetch },\n): Promise<string | null> {\n  const logger = log();\n\n  try {\n    // If already a commit hash, return it\n    if (REGEX_COMMIT_HASH.test(revision)) {\n      return revision;\n    }\n\n    // Get the first commit from listCommits - this is the HEAD\n    for await (const commit of listCommits({\n      repo,\n      revision,\n      ...params,\n    })) {\n      // The commit object structure varies, so we check multiple possible properties\n      const commitHash = (commit as any).oid || (commit as any).id || (commit as any).commitId;\n      if (commitHash) {\n        return commitHash;\n      }\n      break; // Only need the first one\n    }\n\n    logger.error({ repo: toRepoId(repo), revision }, 'No commits found for revision');\n    return null;\n  } catch (error) {\n    logger.error(\n      { error: (error as Error).message, repo: toRepoId(repo), revision },\n      'Error getting HEAD commit',\n    );\n    throw error;\n  }\n}\n\n/**\n * Create a symbolic link following HuggingFace's implementation\n */\nasync function createSymlink(sourcePath: string, targetPath: string): Promise<void> {\n  const logger = log();\n  const { symlink, rm, copyFile } = await import('node:fs/promises');\n\n  // Expand ~ to home directory\n  function expandUser(path: string): string {\n    if (path.startsWith('~')) {\n      return path.replace('~', homedir());\n    }\n    return path;\n  }\n\n  const absSrc = resolve(expandUser(sourcePath));\n  const absDst = resolve(expandUser(targetPath));\n\n  // Remove existing file/symlink if it exists\n  try {\n    await rm(absDst);\n  } catch {\n    // Ignore - file might not exist\n  }\n\n  try {\n    // Create relative symlink (better for portability)\n    const relativePath = relative(dirname(absDst), absSrc);\n    await symlink(relativePath, absDst);\n    logger.debug({ source: absSrc, target: absDst, relative: relativePath }, 'Created symlink');\n  } catch (symlinkError) {\n    // Symlink failed (common on Windows without admin rights)\n    // Fall back to copying the file\n    logger.warn({ source: absSrc, target: absDst }, 'Symlink not supported, falling back to copy');\n    try {\n      await copyFile(absSrc, absDst);\n      logger.debug({ source: absSrc, target: absDst }, 'File copied successfully');\n    } catch (copyError) {\n      logger.error(\n        { error: (copyError as Error).message, source: absSrc, target: absDst },\n        'Failed to copy file',\n      );\n      // If copy also fails, throw the original symlink error\n      throw symlinkError;\n    }\n  }\n}\n\nfunction getFilePointer(storageFolder: string, revision: string, relativeFilename: string): string {\n  const snapshotPath = join(storageFolder, 'snapshots');\n  return join(snapshotPath, revision, relativeFilename);\n}\n\n/**\n * handy method to check if a file exists, or the pointer of a symlinks exists\n */\nasync function exists(path: string, followSymlinks?: boolean): Promise<boolean> {\n  try {\n    if (followSymlinks) {\n      await stat(path);\n    } else {\n      await lstat(path);\n    }\n    return true;\n  } catch (err: unknown) {\n    return false;\n  }\n}\n\nasync function saveRevisionMapping({\n  storageFolder,\n  revision,\n  commitHash,\n}: {\n  storageFolder: string;\n  revision: string;\n  commitHash: string;\n}): Promise<void> {\n  if (!REGEX_COMMIT_HASH.test(revision) && revision !== commitHash) {\n    const refsPath = join(storageFolder, 'refs');\n    await mkdir(refsPath, { recursive: true });\n    writeFileSync(join(refsPath, revision), commitHash);\n  }\n}\n\n/**\n * Download a given file if it's not already present in the local cache.\n * Matches Python's hf_hub_download behavior by using branch HEAD commits.\n */\nexport async function downloadFileToCacheDir(\n  params: {\n    repo: RepoDesignation;\n    path: string;\n    /**\n     * If true, will download the raw git file.\n     */\n    raw?: boolean;\n    /**\n     * An optional Git revision id which can be a branch name, a tag, or a commit hash.\n     * @default \"main\"\n     */\n    revision?: string;\n    hubUrl?: string;\n    cacheDir?: string;\n    /**\n     * Custom fetch function to use instead of the default one\n     */\n    fetch?: typeof fetch;\n    /**\n     * If true, only return cached files, don't download\n     */\n    localFileOnly?: boolean;\n  } & Partial<CredentialsParams>,\n): Promise<string> {\n  const logger = log();\n\n  // get revision provided or default to main\n  const revision = params.revision ?? 'main';\n  const cacheDir = params.cacheDir ?? getHFHubCachePath();\n  // get repo id\n  const repoId = toRepoId(params.repo);\n  // get storage folder\n  const storageFolder = join(cacheDir, getRepoFolderName(repoId));\n\n  let branchHeadCommit: string | undefined;\n\n  // if user provides a commitHash as revision, use it directly\n  if (REGEX_COMMIT_HASH.test(revision)) {\n    branchHeadCommit = revision;\n    const pointerPath = getFilePointer(storageFolder, revision, params.path);\n    if (await exists(pointerPath, true)) {\n      logger.debug(\n        { pointerPath, commitHash: branchHeadCommit },\n        'File found in cache (commit hash)',\n      );\n      return pointerPath;\n    }\n  }\n\n  // If localFileOnly, check cache without making API calls\n  if (params.localFileOnly) {\n    logger.debug({ repoId, path: params.path, revision }, 'Local file only mode - checking cache');\n\n    // Check with revision as-is (in case it's a commit hash)\n    const directPath = getFilePointer(storageFolder, revision, params.path);\n    if (await exists(directPath, true)) {\n      logger.debug({ directPath }, 'File found in cache (direct path)');\n      return directPath;\n    }\n\n    // If revision is not a commit hash, try to resolve from refs\n    if (!REGEX_COMMIT_HASH.test(revision)) {\n      const refsPath = join(storageFolder, 'refs', revision);\n      try {\n        const { readFileSync } = await import('fs');\n        const resolvedHash = readFileSync(refsPath, 'utf-8').trim();\n        const resolvedPath = getFilePointer(storageFolder, resolvedHash, params.path);\n        if (await exists(resolvedPath, true)) {\n          logger.debug({ resolvedPath, resolvedHash }, 'File found in cache (via refs)');\n          return resolvedPath;\n        }\n      } catch {\n        logger.debug({ revision }, 'No ref mapping found for revision');\n      }\n    }\n\n    const error = `File not found in cache: ${repoId}/${params.path} (revision: ${revision}). Make sure to run the download-files command before running the agent worker.`;\n    logger.error({ repoId, path: params.path, revision }, error);\n    throw new Error(error);\n  }\n\n  // Get the branch HEAD commit if not already a commit hash\n  if (!branchHeadCommit) {\n    const headCommit = await getBranchHeadCommit(params.repo, revision, params);\n    if (!headCommit) {\n      throw new Error(`Failed to resolve revision ${revision} to commit hash`);\n    }\n    branchHeadCommit = headCommit;\n  }\n\n  // Check if file exists with the branch HEAD commit\n  const pointerPath = getFilePointer(storageFolder, branchHeadCommit, params.path);\n  if (await exists(pointerPath, true)) {\n    logger.debug({ pointerPath, branchHeadCommit }, 'File found in cache (branch HEAD)');\n\n    await saveRevisionMapping({\n      storageFolder,\n      revision,\n      commitHash: branchHeadCommit,\n    });\n\n    return pointerPath;\n  }\n\n  // Now get file metadata to download it\n  logger.debug(\n    { repoId, path: params.path, revision: branchHeadCommit },\n    'Fetching path info from HF API',\n  );\n  const pathsInformation: (PathInfo & { lastCommit: CommitInfo })[] = await pathsInfo({\n    ...params,\n    paths: [params.path],\n    revision: branchHeadCommit, // Use HEAD commit for consistency\n    expand: true,\n  });\n\n  if (!pathsInformation || pathsInformation.length !== 1) {\n    const error = `cannot get path info for ${params.path}`;\n    logger.error({ repoId, path: params.path, pathsInfoLength: pathsInformation?.length }, error);\n    throw new Error(error);\n  }\n\n  const pathInfo = pathsInformation[0];\n  if (!pathInfo) {\n    const error = `No path info returned for ${params.path}`;\n    logger.error({ repoId, path: params.path }, error);\n    throw new Error(error);\n  }\n\n  let etag: string;\n  if (pathInfo.lfs) {\n    etag = pathInfo.lfs.oid; // get the LFS pointed file oid\n    logger.debug({ etag, path: params.path }, 'File is LFS pointer');\n  } else {\n    etag = pathInfo.oid; // get the repo file if not a LFS pointer\n    logger.debug({ etag, path: params.path }, 'File is regular git object');\n  }\n\n  const blobPath = join(storageFolder, 'blobs', etag);\n\n  logger.debug({ branchHeadCommit, pointerPath, blobPath }, 'Computed cache paths');\n\n  // mkdir blob and pointer path parent directory\n  await mkdir(dirname(blobPath), { recursive: true });\n  await mkdir(dirname(pointerPath), { recursive: true });\n\n  // We might already have the blob but not the pointer\n  // shortcut the download if needed\n  if (await exists(blobPath)) {\n    logger.debug({ blobPath, etag }, 'Blob already exists in cache, creating symlink only');\n    // create symlinks in snapshot folder to blob object\n    await createSymlink(blobPath, pointerPath);\n    return pointerPath;\n  }\n\n  const incomplete = `${blobPath}.incomplete`;\n  logger.debug({ path: params.path, incomplete }, 'Starting file download');\n\n  // Use enhanced download with retry - use branch HEAD commit for download\n  const blob: Blob | null = await downloadFile({\n    ...params,\n    revision: branchHeadCommit,\n  });\n\n  if (!blob) {\n    const error = `invalid response for file ${params.path}`;\n    logger.error({ path: params.path }, error);\n    throw new Error(error);\n  }\n\n  logger.debug({ size: blob.size }, 'Writing blob to disk');\n  await pipeline(Readable.fromWeb(blob.stream() as ReadableStream), createWriteStream(incomplete));\n\n  // rename .incomplete file to expected blob\n  await rename(incomplete, blobPath);\n  logger.debug({ blobPath }, 'Renamed incomplete file to final blob');\n\n  // create symlinks in snapshot folder to blob object\n  await createSymlink(blobPath, pointerPath);\n  logger.debug({ blobPath, pointerPath }, 'Created symlink from snapshot to blob');\n\n  await saveRevisionMapping({\n    storageFolder,\n    revision,\n    commitHash: branchHeadCommit,\n  });\n\n  logger.debug({ pointerPath, size: blob.size }, 'File download completed successfully');\n  return pointerPath;\n}\n"],"mappings":"AAWA,SAAS,cAAc,aAAa,iBAAiB;AACrD,SAAS,WAAW;AACpB,SAAS,mBAAmB,qBAAqB;AACjD,SAAS,OAAO,OAAO,QAAQ,YAAY;AAC3C,SAAS,eAAe;AACxB,SAAS,SAAS,MAAM,UAAU,eAAe;AACjD,SAAS,gBAAgB;AACzB,SAAS,gBAAgB;AAQlB,MAAM,oBAA4B,IAAI,OAAO,gBAAgB;AAGpE,SAAS,kBAAkB,gBAAiC;AAC1D,SAAO,kBAAkB,KAAK,QAAQ,GAAG,UAAU,eAAe,KAAK;AACzE;AAEA,SAAS,kBAAkB,QAAwB;AACjD,SAAO,WAAW,OAAO,QAAQ,OAAO,IAAI,CAAC;AAC/C;AAEA,SAAS,SAAS,MAAwC;AACxD,MAAI,OAAO,SAAS,UAAU;AAC5B,WAAO;AAAA,EACT;AACA,SAAO,GAAG,KAAK,IAAI;AACrB;AAKA,eAAe,oBACb,MACA,UACA,QACwB;AACxB,QAAM,SAAS,IAAI;AAEnB,MAAI;AAEF,QAAI,kBAAkB,KAAK,QAAQ,GAAG;AACpC,aAAO;AAAA,IACT;AAGA,qBAAiB,UAAU,YAAY;AAAA,MACrC;AAAA,MACA;AAAA,MACA,GAAG;AAAA,IACL,CAAC,GAAG;AAEF,YAAM,aAAc,OAAe,OAAQ,OAAe,MAAO,OAAe;AAChF,UAAI,YAAY;AACd,eAAO;AAAA,MACT;AACA;AAAA,IACF;AAEA,WAAO,MAAM,EAAE,MAAM,SAAS,IAAI,GAAG,SAAS,GAAG,+BAA+B;AAChF,WAAO;AAAA,EACT,SAAS,OAAO;AACd,WAAO;AAAA,MACL,EAAE,OAAQ,MAAgB,SAAS,MAAM,SAAS,IAAI,GAAG,SAAS;AAAA,MAClE;AAAA,IACF;AACA,UAAM;AAAA,EACR;AACF;AAKA,eAAe,cAAc,YAAoB,YAAmC;AAClF,QAAM,SAAS,IAAI;AACnB,QAAM,EAAE,SAAS,IAAI,SAAS,IAAI,MAAM,OAAO,kBAAkB;AAGjE,WAAS,WAAW,MAAsB;AACxC,QAAI,KAAK,WAAW,GAAG,GAAG;AACxB,aAAO,KAAK,QAAQ,KAAK,QAAQ,CAAC;AAAA,IACpC;AACA,WAAO;AAAA,EACT;AAEA,QAAM,SAAS,QAAQ,WAAW,UAAU,CAAC;AAC7C,QAAM,SAAS,QAAQ,WAAW,UAAU,CAAC;AAG7C,MAAI;AACF,UAAM,GAAG,MAAM;AAAA,EACjB,QAAQ;AAAA,EAER;AAEA,MAAI;AAEF,UAAM,eAAe,SAAS,QAAQ,MAAM,GAAG,MAAM;AACrD,UAAM,QAAQ,cAAc,MAAM;AAClC,WAAO,MAAM,EAAE,QAAQ,QAAQ,QAAQ,QAAQ,UAAU,aAAa,GAAG,iBAAiB;AAAA,EAC5F,SAAS,cAAc;AAGrB,WAAO,KAAK,EAAE,QAAQ,QAAQ,QAAQ,OAAO,GAAG,6CAA6C;AAC7F,QAAI;AACF,YAAM,SAAS,QAAQ,MAAM;AAC7B,aAAO,MAAM,EAAE,QAAQ,QAAQ,QAAQ,OAAO,GAAG,0BAA0B;AAAA,IAC7E,SAAS,WAAW;AAClB,aAAO;AAAA,QACL,EAAE,OAAQ,UAAoB,SAAS,QAAQ,QAAQ,QAAQ,OAAO;AAAA,QACtE;AAAA,MACF;AAEA,YAAM;AAAA,IACR;AAAA,EACF;AACF;AAEA,SAAS,eAAe,eAAuB,UAAkB,kBAAkC;AACjG,QAAM,eAAe,KAAK,eAAe,WAAW;AACpD,SAAO,KAAK,cAAc,UAAU,gBAAgB;AACtD;AAKA,eAAe,OAAO,MAAc,gBAA4C;AAC9E,MAAI;AACF,QAAI,gBAAgB;AAClB,YAAM,KAAK,IAAI;AAAA,IACjB,OAAO;AACL,YAAM,MAAM,IAAI;AAAA,IAClB;AACA,WAAO;AAAA,EACT,SAAS,KAAc;AACrB,WAAO;AAAA,EACT;AACF;AAEA,eAAe,oBAAoB;AAAA,EACjC;AAAA,EACA;AAAA,EACA;AACF,GAIkB;AAChB,MAAI,CAAC,kBAAkB,KAAK,QAAQ,KAAK,aAAa,YAAY;AAChE,UAAM,WAAW,KAAK,eAAe,MAAM;AAC3C,UAAM,MAAM,UAAU,EAAE,WAAW,KAAK,CAAC;AACzC,kBAAc,KAAK,UAAU,QAAQ,GAAG,UAAU;AAAA,EACpD;AACF;AAMA,eAAsB,uBACpB,QAuBiB;AACjB,QAAM,SAAS,IAAI;AAGnB,QAAM,WAAW,OAAO,YAAY;AACpC,QAAM,WAAW,OAAO,YAAY,kBAAkB;AAEtD,QAAM,SAAS,SAAS,OAAO,IAAI;AAEnC,QAAM,gBAAgB,KAAK,UAAU,kBAAkB,MAAM,CAAC;AAE9D,MAAI;AAGJ,MAAI,kBAAkB,KAAK,QAAQ,GAAG;AACpC,uBAAmB;AACnB,UAAMA,eAAc,eAAe,eAAe,UAAU,OAAO,IAAI;AACvE,QAAI,MAAM,OAAOA,cAAa,IAAI,GAAG;AACnC,aAAO;AAAA,QACL,EAAE,aAAAA,cAAa,YAAY,iBAAiB;AAAA,QAC5C;AAAA,MACF;AACA,aAAOA;AAAA,IACT;AAAA,EACF;AAGA,MAAI,OAAO,eAAe;AACxB,WAAO,MAAM,EAAE,QAAQ,MAAM,OAAO,MAAM,SAAS,GAAG,uCAAuC;AAG7F,UAAM,aAAa,eAAe,eAAe,UAAU,OAAO,IAAI;AACtE,QAAI,MAAM,OAAO,YAAY,IAAI,GAAG;AAClC,aAAO,MAAM,EAAE,WAAW,GAAG,mCAAmC;AAChE,aAAO;AAAA,IACT;AAGA,QAAI,CAAC,kBAAkB,KAAK,QAAQ,GAAG;AACrC,YAAM,WAAW,KAAK,eAAe,QAAQ,QAAQ;AACrD,UAAI;AACF,cAAM,EAAE,aAAa,IAAI,MAAM,OAAO,IAAI;AAC1C,cAAM,eAAe,aAAa,UAAU,OAAO,EAAE,KAAK;AAC1D,cAAM,eAAe,eAAe,eAAe,cAAc,OAAO,IAAI;AAC5E,YAAI,MAAM,OAAO,cAAc,IAAI,GAAG;AACpC,iBAAO,MAAM,EAAE,cAAc,aAAa,GAAG,gCAAgC;AAC7E,iBAAO;AAAA,QACT;AAAA,MACF,QAAQ;AACN,eAAO,MAAM,EAAE,SAAS,GAAG,mCAAmC;AAAA,MAChE;AAAA,IACF;AAEA,UAAM,QAAQ,4BAA4B,MAAM,IAAI,OAAO,IAAI,eAAe,QAAQ;AACtF,WAAO,MAAM,EAAE,QAAQ,MAAM,OAAO,MAAM,SAAS,GAAG,KAAK;AAC3D,UAAM,IAAI,MAAM,KAAK;AAAA,EACvB;AAGA,MAAI,CAAC,kBAAkB;AACrB,UAAM,aAAa,MAAM,oBAAoB,OAAO,MAAM,UAAU,MAAM;AAC1E,QAAI,CAAC,YAAY;AACf,YAAM,IAAI,MAAM,8BAA8B,QAAQ,iBAAiB;AAAA,IACzE;AACA,uBAAmB;AAAA,EACrB;AAGA,QAAM,cAAc,eAAe,eAAe,kBAAkB,OAAO,IAAI;AAC/E,MAAI,MAAM,OAAO,aAAa,IAAI,GAAG;AACnC,WAAO,MAAM,EAAE,aAAa,iBAAiB,GAAG,mCAAmC;AAEnF,UAAM,oBAAoB;AAAA,MACxB;AAAA,MACA;AAAA,MACA,YAAY;AAAA,IACd,CAAC;AAED,WAAO;AAAA,EACT;AAGA,SAAO;AAAA,IACL,EAAE,QAAQ,MAAM,OAAO,MAAM,UAAU,iBAAiB;AAAA,IACxD;AAAA,EACF;AACA,QAAM,mBAA8D,MAAM,UAAU;AAAA,IAClF,GAAG;AAAA,IACH,OAAO,CAAC,OAAO,IAAI;AAAA,IACnB,UAAU;AAAA;AAAA,IACV,QAAQ;AAAA,EACV,CAAC;AAED,MAAI,CAAC,oBAAoB,iBAAiB,WAAW,GAAG;AACtD,UAAM,QAAQ,4BAA4B,OAAO,IAAI;AACrD,WAAO,MAAM,EAAE,QAAQ,MAAM,OAAO,MAAM,iBAAiB,qDAAkB,OAAO,GAAG,KAAK;AAC5F,UAAM,IAAI,MAAM,KAAK;AAAA,EACvB;AAEA,QAAM,WAAW,iBAAiB,CAAC;AACnC,MAAI,CAAC,UAAU;AACb,UAAM,QAAQ,6BAA6B,OAAO,IAAI;AACtD,WAAO,MAAM,EAAE,QAAQ,MAAM,OAAO,KAAK,GAAG,KAAK;AACjD,UAAM,IAAI,MAAM,KAAK;AAAA,EACvB;AAEA,MAAI;AACJ,MAAI,SAAS,KAAK;AAChB,WAAO,SAAS,IAAI;AACpB,WAAO,MAAM,EAAE,MAAM,MAAM,OAAO,KAAK,GAAG,qBAAqB;AAAA,EACjE,OAAO;AACL,WAAO,SAAS;AAChB,WAAO,MAAM,EAAE,MAAM,MAAM,OAAO,KAAK,GAAG,4BAA4B;AAAA,EACxE;AAEA,QAAM,WAAW,KAAK,eAAe,SAAS,IAAI;AAElD,SAAO,MAAM,EAAE,kBAAkB,aAAa,SAAS,GAAG,sBAAsB;AAGhF,QAAM,MAAM,QAAQ,QAAQ,GAAG,EAAE,WAAW,KAAK,CAAC;AAClD,QAAM,MAAM,QAAQ,WAAW,GAAG,EAAE,WAAW,KAAK,CAAC;AAIrD,MAAI,MAAM,OAAO,QAAQ,GAAG;AAC1B,WAAO,MAAM,EAAE,UAAU,KAAK,GAAG,qDAAqD;AAEtF,UAAM,cAAc,UAAU,WAAW;AACzC,WAAO;AAAA,EACT;AAEA,QAAM,aAAa,GAAG,QAAQ;AAC9B,SAAO,MAAM,EAAE,MAAM,OAAO,MAAM,WAAW,GAAG,wBAAwB;AAGxE,QAAM,OAAoB,MAAM,aAAa;AAAA,IAC3C,GAAG;AAAA,IACH,UAAU;AAAA,EACZ,CAAC;AAED,MAAI,CAAC,MAAM;AACT,UAAM,QAAQ,6BAA6B,OAAO,IAAI;AACtD,WAAO,MAAM,EAAE,MAAM,OAAO,KAAK,GAAG,KAAK;AACzC,UAAM,IAAI,MAAM,KAAK;AAAA,EACvB;AAEA,SAAO,MAAM,EAAE,MAAM,KAAK,KAAK,GAAG,sBAAsB;AACxD,QAAM,SAAS,SAAS,QAAQ,KAAK,OAAO,CAAmB,GAAG,kBAAkB,UAAU,CAAC;AAG/F,QAAM,OAAO,YAAY,QAAQ;AACjC,SAAO,MAAM,EAAE,SAAS,GAAG,uCAAuC;AAGlE,QAAM,cAAc,UAAU,WAAW;AACzC,SAAO,MAAM,EAAE,UAAU,YAAY,GAAG,uCAAuC;AAE/E,QAAM,oBAAoB;AAAA,IACxB;AAAA,IACA;AAAA,IACA,YAAY;AAAA,EACd,CAAC;AAED,SAAO,MAAM,EAAE,aAAa,MAAM,KAAK,KAAK,GAAG,sCAAsC;AACrF,SAAO;AACT;","names":["pointerPath"]}