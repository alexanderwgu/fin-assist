{"version":3,"sources":["../../src/turn_detector/base.ts"],"sourcesContent":["// SPDX-FileCopyrightText: 2025 LiveKit, Inc.\n//\n// SPDX-License-Identifier: Apache-2.0\nimport { type PreTrainedTokenizer } from '@huggingface/transformers';\nimport type { ipc, llm } from '@livekit/agents';\nimport { Future, InferenceRunner, getJobContext, log } from '@livekit/agents';\nimport { readFileSync } from 'node:fs';\nimport os from 'node:os';\nimport { InferenceSession, Tensor } from 'onnxruntime-node';\nimport { downloadFileToCacheDir } from '../hf_utils.js';\nimport {\n  type EOUModelType,\n  HG_MODEL_REPO,\n  MAX_HISTORY_TURNS,\n  MODEL_REVISIONS,\n  ONNX_FILEPATH,\n} from './constants.js';\nimport { normalizeText } from './utils.js';\n\ntype RawChatItem = { role: string; content: string };\n\ntype EOUOutput = { eouProbability: number; input: string; duration: number };\n\nexport abstract class EOURunnerBase extends InferenceRunner<RawChatItem[], EOUOutput> {\n  private modelType: EOUModelType;\n  private modelRevision: string;\n\n  private session?: InferenceSession;\n  private tokenizer?: PreTrainedTokenizer;\n\n  #logger = log();\n\n  constructor(modelType: EOUModelType) {\n    super();\n    this.modelType = modelType;\n    this.modelRevision = MODEL_REVISIONS[modelType];\n  }\n\n  async initialize() {\n    const { AutoTokenizer } = await import('@huggingface/transformers');\n\n    try {\n      const onnxModelPath = await downloadFileToCacheDir({\n        repo: HG_MODEL_REPO,\n        path: ONNX_FILEPATH,\n        revision: this.modelRevision,\n        localFileOnly: true,\n      });\n\n      // TODO(brian): support session config once onnxruntime-node supports it\n      const sessOptions: InferenceSession.SessionOptions = {\n        intraOpNumThreads: Math.max(1, Math.floor(os.cpus().length / 2)),\n        interOpNumThreads: 1,\n        executionProviders: [{ name: 'cpu' }],\n      };\n\n      this.session = await InferenceSession.create(onnxModelPath, sessOptions);\n\n      this.tokenizer = await AutoTokenizer.from_pretrained('livekit/turn-detector', {\n        revision: this.modelRevision,\n        local_files_only: true,\n      });\n    } catch (e) {\n      const errorMessage = String(e);\n\n      // Check if the error is related to missing local files\n      if (\n        errorMessage.includes('local_files_only=true') ||\n        errorMessage.includes('file was not found locally') ||\n        errorMessage.includes('File not found in cache')\n      ) {\n        throw new Error(\n          `agents-plugins-livekit failed to initialize ${this.modelType} EOU turn detector: Required model files not found locally.\\n\\n` +\n            `This usually means you need to download the model files first. Please run one of these commands:\\n\\n` +\n            `  If using Node.js starter template:\\n` +\n            `    pnpm download-files\\n\\n` +\n            `  If using the agent directly:\\n` +\n            `    node ./your_agent.ts download-files\\n\\n` +\n            `Then try running your application again.\\n\\n` +\n            `Original error: ${e}`,\n        );\n      }\n\n      throw new Error(\n        `agents-plugins-livekit failed to initialize ${this.modelType} EOU turn detector: ${e}`,\n      );\n    }\n  }\n\n  async run(data: RawChatItem[]) {\n    const startTime = Date.now();\n\n    const text = this.formatChatCtx(data);\n\n    const inputs = this.tokenizer!.encode(text, { add_special_tokens: false });\n    this.#logger.debug({ inputs: JSON.stringify(inputs), text }, 'EOU inputs');\n\n    const outputs = await this.session!.run(\n      { input_ids: new Tensor('int64', inputs, [1, inputs.length]) },\n      ['prob'],\n    );\n\n    const probData = outputs.prob!.data;\n    // should be the logits of the last token\n    const eouProbability = probData[probData.length - 1] as number;\n    const endTime = Date.now();\n\n    const result = {\n      eouProbability,\n      input: text,\n      duration: (endTime - startTime) / 1000,\n    };\n\n    this.#logger.child({ result }).debug('eou prediction');\n    return result;\n  }\n\n  async close() {\n    await this.session?.release();\n  }\n\n  private formatChatCtx(chatCtx: RawChatItem[]): string {\n    const newChatCtx: RawChatItem[] = [];\n    let lastMsg: RawChatItem | undefined = undefined;\n\n    for (const msg of chatCtx) {\n      const content = msg.content;\n      if (!content) continue;\n\n      const norm = normalizeText(content);\n\n      // need to combine adjacent turns together to match training data\n      if (lastMsg !== undefined && lastMsg.role === msg.role) {\n        lastMsg.content += ` ${norm}`;\n      } else {\n        newChatCtx.push({ role: msg.role, content: norm });\n        lastMsg = newChatCtx[newChatCtx.length - 1]!;\n      }\n    }\n\n    // TODO(brian): investigate add_special_tokens options\n    const convoText = this.tokenizer!.apply_chat_template(newChatCtx, {\n      add_generation_prompt: false,\n      tokenize: false,\n    }) as string;\n\n    // remove the EOU token from current utterance\n    return convoText.slice(0, convoText.lastIndexOf('<|im_end|>'));\n  }\n}\n\nexport interface EOUModelOptions {\n  modelType: EOUModelType;\n  executor?: ipc.InferenceExecutor;\n  unlikelyThreshold?: number;\n  loadLanguages?: boolean;\n}\n\ntype LanguageData = {\n  threshold: number;\n};\n\nexport abstract class EOUModel {\n  private modelType: EOUModelType;\n  private executor: ipc.InferenceExecutor;\n  private threshold: number | undefined;\n  private loadLanguages: boolean;\n\n  protected languagesFuture: Future<Record<string, LanguageData>> = new Future();\n\n  #logger = log();\n\n  constructor(opts: EOUModelOptions) {\n    const {\n      modelType = 'en',\n      executor = getJobContext().inferenceExecutor,\n      unlikelyThreshold,\n      loadLanguages = true,\n    } = opts;\n\n    this.modelType = modelType;\n    this.executor = executor;\n    this.threshold = unlikelyThreshold;\n    this.loadLanguages = loadLanguages;\n\n    if (loadLanguages) {\n      downloadFileToCacheDir({\n        repo: HG_MODEL_REPO,\n        path: 'languages.json',\n        revision: MODEL_REVISIONS[modelType],\n        localFileOnly: true,\n      }).then((path) => {\n        this.languagesFuture.resolve(JSON.parse(readFileSync(path, 'utf8')));\n      });\n    }\n  }\n\n  async unlikelyThreshold(language?: string): Promise<number | undefined> {\n    if (language === undefined) {\n      return this.threshold;\n    }\n\n    const lang = language.toLowerCase();\n    const languages = await this.languagesFuture.await;\n\n    // try the full language code first\n    let langData = languages[lang];\n\n    if (langData === undefined && lang.includes('-')) {\n      const baseLang = lang.split('-')[0]!;\n      langData = languages[baseLang];\n    }\n\n    if (langData === undefined) {\n      this.#logger.warn(`Language ${language} not supported by EOU model`);\n      return undefined;\n    }\n\n    // if a custom threshold is provided, use it\n    return this.threshold !== undefined ? this.threshold : langData.threshold;\n  }\n\n  async supportsLanguage(language?: string): Promise<boolean> {\n    return (await this.unlikelyThreshold(language)) !== undefined;\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unused-vars\n  async predictEndOfTurn(chatCtx: llm.ChatContext, timeout: number = 3): Promise<number> {\n    let messages: RawChatItem[] = [];\n\n    for (const message of chatCtx.items) {\n      // skip system and developer messages or tool call messages\n      if (message.type !== 'message' || message.role in ['system', 'developer']) {\n        continue;\n      }\n\n      for (const content of message.content) {\n        if (typeof content === 'string') {\n          messages.push({\n            role: message.role === 'assistant' ? 'assistant' : 'user',\n            content: content,\n          });\n        }\n      }\n    }\n\n    messages = messages.slice(-MAX_HISTORY_TURNS);\n\n    const result = await this.executor.doInference(this.inferenceMethod(), messages);\n    if (result === undefined) {\n      throw new Error('EOU inference should always returns a result');\n    }\n\n    return (result as EOUOutput).eouProbability;\n  }\n\n  abstract inferenceMethod(): string;\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA,0BAAyC;AAEzC,oBAA4D;AAC5D,qBAA6B;AAC7B,qBAAe;AACf,8BAAyC;AACzC,sBAAuC;AACvC,uBAMO;AACP,mBAA8B;AAMvB,MAAe,sBAAsB,8BAA0C;AAAA,EAC5E;AAAA,EACA;AAAA,EAEA;AAAA,EACA;AAAA,EAER,cAAU,mBAAI;AAAA,EAEd,YAAY,WAAyB;AACnC,UAAM;AACN,SAAK,YAAY;AACjB,SAAK,gBAAgB,iCAAgB,SAAS;AAAA,EAChD;AAAA,EAEA,MAAM,aAAa;AACjB,UAAM,EAAE,cAAc,IAAI,MAAM,OAAO,2BAA2B;AAElE,QAAI;AACF,YAAM,gBAAgB,UAAM,wCAAuB;AAAA,QACjD,MAAM;AAAA,QACN,MAAM;AAAA,QACN,UAAU,KAAK;AAAA,QACf,eAAe;AAAA,MACjB,CAAC;AAGD,YAAM,cAA+C;AAAA,QACnD,mBAAmB,KAAK,IAAI,GAAG,KAAK,MAAM,eAAAA,QAAG,KAAK,EAAE,SAAS,CAAC,CAAC;AAAA,QAC/D,mBAAmB;AAAA,QACnB,oBAAoB,CAAC,EAAE,MAAM,MAAM,CAAC;AAAA,MACtC;AAEA,WAAK,UAAU,MAAM,yCAAiB,OAAO,eAAe,WAAW;AAEvE,WAAK,YAAY,MAAM,cAAc,gBAAgB,yBAAyB;AAAA,QAC5E,UAAU,KAAK;AAAA,QACf,kBAAkB;AAAA,MACpB,CAAC;AAAA,IACH,SAAS,GAAG;AACV,YAAM,eAAe,OAAO,CAAC;AAG7B,UACE,aAAa,SAAS,uBAAuB,KAC7C,aAAa,SAAS,4BAA4B,KAClD,aAAa,SAAS,yBAAyB,GAC/C;AACA,cAAM,IAAI;AAAA,UACR,+CAA+C,KAAK,SAAS;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAOxC,CAAC;AAAA,QACxB;AAAA,MACF;AAEA,YAAM,IAAI;AAAA,QACR,+CAA+C,KAAK,SAAS,uBAAuB,CAAC;AAAA,MACvF;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,IAAI,MAAqB;AAC7B,UAAM,YAAY,KAAK,IAAI;AAE3B,UAAM,OAAO,KAAK,cAAc,IAAI;AAEpC,UAAM,SAAS,KAAK,UAAW,OAAO,MAAM,EAAE,oBAAoB,MAAM,CAAC;AACzE,SAAK,QAAQ,MAAM,EAAE,QAAQ,KAAK,UAAU,MAAM,GAAG,KAAK,GAAG,YAAY;AAEzE,UAAM,UAAU,MAAM,KAAK,QAAS;AAAA,MAClC,EAAE,WAAW,IAAI,+BAAO,SAAS,QAAQ,CAAC,GAAG,OAAO,MAAM,CAAC,EAAE;AAAA,MAC7D,CAAC,MAAM;AAAA,IACT;AAEA,UAAM,WAAW,QAAQ,KAAM;AAE/B,UAAM,iBAAiB,SAAS,SAAS,SAAS,CAAC;AACnD,UAAM,UAAU,KAAK,IAAI;AAEzB,UAAM,SAAS;AAAA,MACb;AAAA,MACA,OAAO;AAAA,MACP,WAAW,UAAU,aAAa;AAAA,IACpC;AAEA,SAAK,QAAQ,MAAM,EAAE,OAAO,CAAC,EAAE,MAAM,gBAAgB;AACrD,WAAO;AAAA,EACT;AAAA,EAEA,MAAM,QAAQ;AArHhB;AAsHI,YAAM,UAAK,YAAL,mBAAc;AAAA,EACtB;AAAA,EAEQ,cAAc,SAAgC;AACpD,UAAM,aAA4B,CAAC;AACnC,QAAI,UAAmC;AAEvC,eAAW,OAAO,SAAS;AACzB,YAAM,UAAU,IAAI;AACpB,UAAI,CAAC,QAAS;AAEd,YAAM,WAAO,4BAAc,OAAO;AAGlC,UAAI,YAAY,UAAa,QAAQ,SAAS,IAAI,MAAM;AACtD,gBAAQ,WAAW,IAAI,IAAI;AAAA,MAC7B,OAAO;AACL,mBAAW,KAAK,EAAE,MAAM,IAAI,MAAM,SAAS,KAAK,CAAC;AACjD,kBAAU,WAAW,WAAW,SAAS,CAAC;AAAA,MAC5C;AAAA,IACF;AAGA,UAAM,YAAY,KAAK,UAAW,oBAAoB,YAAY;AAAA,MAChE,uBAAuB;AAAA,MACvB,UAAU;AAAA,IACZ,CAAC;AAGD,WAAO,UAAU,MAAM,GAAG,UAAU,YAAY,YAAY,CAAC;AAAA,EAC/D;AACF;AAaO,MAAe,SAAS;AAAA,EACrB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EAEE,kBAAwD,IAAI,qBAAO;AAAA,EAE7E,cAAU,mBAAI;AAAA,EAEd,YAAY,MAAuB;AACjC,UAAM;AAAA,MACJ,YAAY;AAAA,MACZ,eAAW,6BAAc,EAAE;AAAA,MAC3B;AAAA,MACA,gBAAgB;AAAA,IAClB,IAAI;AAEJ,SAAK,YAAY;AACjB,SAAK,WAAW;AAChB,SAAK,YAAY;AACjB,SAAK,gBAAgB;AAErB,QAAI,eAAe;AACjB,kDAAuB;AAAA,QACrB,MAAM;AAAA,QACN,MAAM;AAAA,QACN,UAAU,iCAAgB,SAAS;AAAA,QACnC,eAAe;AAAA,MACjB,CAAC,EAAE,KAAK,CAAC,SAAS;AAChB,aAAK,gBAAgB,QAAQ,KAAK,UAAM,6BAAa,MAAM,MAAM,CAAC,CAAC;AAAA,MACrE,CAAC;AAAA,IACH;AAAA,EACF;AAAA,EAEA,MAAM,kBAAkB,UAAgD;AACtE,QAAI,aAAa,QAAW;AAC1B,aAAO,KAAK;AAAA,IACd;AAEA,UAAM,OAAO,SAAS,YAAY;AAClC,UAAM,YAAY,MAAM,KAAK,gBAAgB;AAG7C,QAAI,WAAW,UAAU,IAAI;AAE7B,QAAI,aAAa,UAAa,KAAK,SAAS,GAAG,GAAG;AAChD,YAAM,WAAW,KAAK,MAAM,GAAG,EAAE,CAAC;AAClC,iBAAW,UAAU,QAAQ;AAAA,IAC/B;AAEA,QAAI,aAAa,QAAW;AAC1B,WAAK,QAAQ,KAAK,YAAY,QAAQ,6BAA6B;AACnE,aAAO;AAAA,IACT;AAGA,WAAO,KAAK,cAAc,SAAY,KAAK,YAAY,SAAS;AAAA,EAClE;AAAA,EAEA,MAAM,iBAAiB,UAAqC;AAC1D,WAAQ,MAAM,KAAK,kBAAkB,QAAQ,MAAO;AAAA,EACtD;AAAA;AAAA,EAGA,MAAM,iBAAiB,SAA0B,UAAkB,GAAoB;AACrF,QAAI,WAA0B,CAAC;AAE/B,eAAW,WAAW,QAAQ,OAAO;AAEnC,UAAI,QAAQ,SAAS,aAAa,QAAQ,QAAQ,CAAC,UAAU,WAAW,GAAG;AACzE;AAAA,MACF;AAEA,iBAAW,WAAW,QAAQ,SAAS;AACrC,YAAI,OAAO,YAAY,UAAU;AAC/B,mBAAS,KAAK;AAAA,YACZ,MAAM,QAAQ,SAAS,cAAc,cAAc;AAAA,YACnD;AAAA,UACF,CAAC;AAAA,QACH;AAAA,MACF;AAAA,IACF;AAEA,eAAW,SAAS,MAAM,CAAC,kCAAiB;AAE5C,UAAM,SAAS,MAAM,KAAK,SAAS,YAAY,KAAK,gBAAgB,GAAG,QAAQ;AAC/E,QAAI,WAAW,QAAW;AACxB,YAAM,IAAI,MAAM,8CAA8C;AAAA,IAChE;AAEA,WAAQ,OAAqB;AAAA,EAC/B;AAGF;","names":["os"]}